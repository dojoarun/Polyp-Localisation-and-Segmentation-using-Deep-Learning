{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16 fine tuning for colonoscopy polyps\n",
    "\n",
    "In the previous notebook ([4-TransferLearning.ipynb](4-TransferLearning.ipynb)) I tested the VGG16 transfer learning by training only the last FC layer. All the other convolutions blocks had the weights from the pre-trained VGG16.\n",
    "\n",
    "This notebook, I will try to apply a fine tuning: to train 1 or 2 convolutional blocks + FC layer. The FC layer will use initial weights from the best model obtained in the previous step (Transfer Learning notebook). See more details at [Keras blog](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html).\n",
    "\n",
    "Let's load some libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import with_statement\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from numpy.random import seed\n",
    "from tensorflow import set_random_seed\n",
    "import time, os\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of paths for dataset, previous trained weights for the FC layer, earlystopping model, etc.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder to save the models\n",
    "modelFolder = 'saved_models'\n",
    "\n",
    "# Path to the file with the weights of the pre-trained VGG16 model\n",
    "weights_path = 'C:/Users/lenovo/Desktop/Final Project/nets/vgg16_weights.h5'\n",
    "\n",
    "# Path to the previous saved top model weights (FC layer trained in Transfer Learning notebook)\n",
    "top_model_weights_path = os.path.join(modelFolder,'transferVGG16_bottleneck_fc_model.h5')\n",
    "\n",
    "# Earlystoping saved model - this name will be modified later by including parameter values\n",
    "earlystoping_path = 'C:/Users/lenovo/Desktop/Final Project/saved_models/fineTunning_earlystopnning.h5'\n",
    "\n",
    "# Dimensions of our images\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "# Train & validation images folders\n",
    "train_data_dir      = 'C:/Users/lenovo/Desktop/Final Project/data_polyps/train'\n",
    "validation_data_dir = 'C:/Users/lenovo/Desktop/Final Project/data_polyps/validation'\n",
    "\n",
    "# Train parameters\n",
    "nb_train_samples      = 910 # number of samples for training\n",
    "nb_validation_samples = 302 # number of samples for validation\n",
    "epochs = 300\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of the function that will do a fine tuning of the pre-trained VGG16 using FC layer weights trained in the previous notebook:\n",
    "* Load the pre-trained VGG16 as the lower model,\n",
    "* Add the top model as a FC layer,\n",
    "* Load the previous calculated weights for the FC layer,\n",
    "* Freeze a number of layers (a specific number of convolutional blocks): to freeze the last Conv block, freeze 15 layers; to freeze 2 last conv blocks, freeze only 11 layers.\n",
    "* Compilte the computational graph of the model,\n",
    "* Generate training & validation datasets from folders using data augmentation,\n",
    "* Use earlystopping if the validation accuracy is not increasing in 10 iterations,\n",
    "* Save the last best model,\n",
    "* Use SGD optimizer,\n",
    "* Search the best model using different values for the main hyperparameters: epochs, batch size, learning rate, momentum, and the number of layers to freeze.\n",
    "\n",
    "See more details at [Keras blog](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html).\n",
    "\n",
    "In the first step, I will try one set of parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FineTunningVGG(epochs, batch_size, learning, mom, freezeLayers):\n",
    "    # Fine tuning function using VGG16 and our weights for the FC layer (top model)\n",
    "    \n",
    "    # Set seeeds for reproductibility\n",
    "    seed(1)            # numpy seed\n",
    "    set_random_seed(2) # tensorflow seed\n",
    "    \n",
    "    # Build the VGG16 block using our input size 150, 150, 3\n",
    "    base_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(150,150,3))\n",
    "\n",
    "    # Build a classifier model to put on top of the convolutional model (FC layer / top model)\n",
    "    top_model = Sequential()\n",
    "    top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "    top_model.add(Dense(256, activation='relu'))\n",
    "    top_model.add(Dropout(0.5))\n",
    "    top_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Is necessary to start with a fully-trained classifier, including the top classifier,\n",
    "    # in order to successfully do fine-tuning\n",
    "    \n",
    "    # Load the previous calculated weight for the top model\n",
    "    top_model.load_weights(top_model_weights_path)\n",
    "\n",
    "    # Add the model on top of the convolutional base\n",
    "    model = Model(inputs= base_model.input, outputs= top_model(base_model.output))\n",
    "\n",
    "    # Set the first 'freezeLayers' layers to non-trainable (weights will not be updated)\n",
    "    # This number depends on the blocks to freeze: for the last Conv block freeze 15 layers,\n",
    "    # to freeze 2 last conv blocks freeze only 11 layers.\n",
    "    for layer in model.layers[:freezeLayers]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Compile the model with a SGD/momentum optimizer and a very slow learning rate.\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer= optimizers.SGD(lr=learning, momentum=mom), # lr=1e-4, momentum=0.9\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Prepare data augmentation configuration\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale = 1. / 255,\n",
    "        shear_range = 0.2,\n",
    "        zoom_range = 0.2,\n",
    "        horizontal_flip = True,\n",
    "        vertical_flip = True,\n",
    "        rotation_range = 90)\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    # Generate training and validation data\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "    validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "    # Start timer\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Use earlystopping:\n",
    "    callbacks=[EarlyStopping(\n",
    "                            monitor='val_acc', \n",
    "                            patience=10,\n",
    "                            mode='max',\n",
    "                            verbose=1),\n",
    "                ModelCheckpoint(earlystoping_path[:-3]+'_e'+str(epochs)+'b'+str(batch_size)+'l'+str(learning)+'m'+str(mom)+'f'+str(freezeLayers)+'.h5',\n",
    "                            monitor='val_acc', \n",
    "                            save_best_only=True, \n",
    "                            mode='max',\n",
    "                            verbose=0)]\n",
    "\n",
    "    # Fine-tune the model\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_validation_samples // batch_size,\n",
    "        workers=7, # 7 cores of the CPU!\n",
    "        verbose = 0,\n",
    "        callbacks=callbacks) # remove this param if you dont need early stopping\n",
    "\n",
    "    # Print training time\n",
    "    print(\"Training time: %0.1f mins ---\" % ((time.time() - start_time)/60))\n",
    "\n",
    "    # Evaluate final test loss and accuracy scores\n",
    "    scoresVal = model.evaluate_generator(validation_generator, nb_validation_samples//batch_size, workers=7)\n",
    "    scoresTr  = model.evaluate_generator(train_generator, nb_train_samples//batch_size, workers=7)\n",
    "    # Print the results\n",
    "    print(freezeLayers, learning, mom, epochs, batch_size, scoresTr[0], scoresVal[0], scoresTr[1], scoresVal[1])\n",
    "\n",
    "    # clean some memory\n",
    "    del base_model\n",
    "    del top_model\n",
    "    del model\n",
    "\n",
    "    del train_datagen\n",
    "    del train_generator\n",
    "    del validation_generator\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last Conv block + FC training\n",
    "\n",
    "Let's try the fine tuning for FC and only the last Conv block using `SGD` and earlystopping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[3,3,3,64] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator mklcpu\n\t [[node block1_conv1_1/random_uniform/RandomUniform (defined at C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4139) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nOriginal stack trace for 'block1_conv1_1/random_uniform/RandomUniform':\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\asyncio\\base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2854, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2880, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3057, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3248, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3325, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-72e113dbf170>\", line 1, in <module>\n    FineTunningVGG(200, 64, 1e-4,  0.9, 15)\n  File \"<ipython-input-6-d37e3a04dee0>\", line 9, in FineTunningVGG\n    base_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(150,150,3))\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\keras\\applications\\__init__.py\", line 28, in wrapper\n    return base_fun(*args, **kwargs)\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\keras\\applications\\vgg16.py\", line 11, in VGG16\n    return vgg16.VGG16(*args, **kwargs)\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\keras_applications\\vgg16.py\", line 112, in VGG16\n    name='block1_conv1')(img_input)\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 431, in __call__\n    self.build(unpack_singleton(input_shapes))\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 141, in build\n    constraint=self.kernel_constraint)\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 249, in add_weight\n    weight = K.variable(initializer(shape),\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\keras\\initializers.py\", line 218, in __call__\n    dtype=dtype, seed=self.seed)\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 4139, in random_uniform\n    dtype=dtype, seed=seed)\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\random_ops.py\", line 247, in random_uniform\n    rnd = gen_random_ops.random_uniform(shape, dtype, seed=seed1, seed2=seed2)\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_random_ops.py\", line 819, in random_uniform\n    name=name)\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1355\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1356\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1357\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1341\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1429\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[3,3,3,64] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator mklcpu\n\t [[{{node block1_conv1_1/random_uniform/RandomUniform}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-72e113dbf170>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mFineTunningVGG\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1e-4\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;36m0.9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-d37e3a04dee0>\u001b[0m in \u001b[0;36mFineTunningVGG\u001b[1;34m(epochs, batch_size, learning, mom, freezeLayers)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# Build the VGG16 block using our input size 150, 150, 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mbase_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapplications\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVGG16\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'imagenet'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# Build a classifier model to put on top of the convolutional model (FC layer / top model)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\applications\\__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'models'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'utils'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbase_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\applications\\vgg16.py\u001b[0m in \u001b[0;36mVGG16\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mkeras_modules_injection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mvgg16\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVGG16\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras_applications\\vgg16.py\u001b[0m in \u001b[0;36mVGG16\u001b[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m                 \u001b[0mcache_subdir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'models'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m                 file_hash='6d6bbae143d832006294945121d1f1fc')\n\u001b[1;32m--> 210\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'theano'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m             \u001b[0mkeras_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_all_kernels_in_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[0;32m   1164\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1165\u001b[0m                 saving.load_weights_from_hdf5_group(\n\u001b[1;32m-> 1166\u001b[1;33m                     f, self.layers, reshape=reshape)\n\u001b[0m\u001b[0;32m   1167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1168\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[1;34m(f, layers, reshape)\u001b[0m\n\u001b[0;32m   1056\u001b[0m                              ' elements.')\n\u001b[0;32m   1057\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1058\u001b[1;33m     \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1059\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[1;34m(tuples)\u001b[0m\n\u001b[0;32m   2468\u001b[0m             \u001b[0massign_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2469\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2470\u001b[1;33m         \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0massign_ops\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2471\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2472\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[1;34m()\u001b[0m\n\u001b[0;32m    204\u001b[0m                     \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m                     \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;31m# hack for list_devices() function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[1;31m# list_devices() function is not available under tensorflow r1.3.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 950\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    951\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1171\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1173\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1174\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1350\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1368\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1370\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1372\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[3,3,3,64] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator mklcpu\n\t [[node block1_conv1_1/random_uniform/RandomUniform (defined at C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4139) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nOriginal stack trace for 'block1_conv1_1/random_uniform/RandomUniform':\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\asyncio\\base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2854, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2880, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3057, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3248, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3325, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-72e113dbf170>\", line 1, in <module>\n    FineTunningVGG(200, 64, 1e-4,  0.9, 15)\n  File \"<ipython-input-6-d37e3a04dee0>\", line 9, in FineTunningVGG\n    base_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(150,150,3))\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\keras\\applications\\__init__.py\", line 28, in wrapper\n    return base_fun(*args, **kwargs)\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\keras\\applications\\vgg16.py\", line 11, in VGG16\n    return vgg16.VGG16(*args, **kwargs)\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\keras_applications\\vgg16.py\", line 112, in VGG16\n    name='block1_conv1')(img_input)\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 431, in __call__\n    self.build(unpack_singleton(input_shapes))\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 141, in build\n    constraint=self.kernel_constraint)\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 249, in add_weight\n    weight = K.variable(initializer(shape),\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\keras\\initializers.py\", line 218, in __call__\n    dtype=dtype, seed=self.seed)\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 4139, in random_uniform\n    dtype=dtype, seed=seed)\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\random_ops.py\", line 247, in random_uniform\n    rnd = gen_random_ops.random_uniform(shape, dtype, seed=seed1, seed2=seed2)\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_random_ops.py\", line 819, in random_uniform\n    name=name)\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "FineTunningVGG(200, 64, 1e-4,  0.9, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even after 200 epochs, the model is underfitter (validation ACC 92.9% vs training ACC 90.8%). We could decrease the drop rate but we are using the same top model for loading the weights.\n",
    "\n",
    "In the second step, let's try to use different paramters. You should use more values! With this function, you can search for several hyperparamters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-1ae250b6a0f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Start total timer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Change your hyperparamters to search for\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfreezeLayersValues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# 15 = freeze last Conv block, 11 = freeze last 2 Conv blocks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "# Start total timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Change your hyperparamters to search for\n",
    "freezeLayersValues = [15] # 15 = freeze last Conv block, 11 = freeze last 2 Conv blocks\n",
    "learningValues = [1e-6, 1e-5, 1e-4, 5e-4, 1e-3]\n",
    "monValues = [0.8, 0.9]\n",
    "epochsValues = [100]\n",
    "batch_sizeValues = [64]\n",
    "\n",
    "# Print a header for results\n",
    "print('Freeze', 'Learning', 'Momentum', 'epochs', 'batch_size', 'Loss_Tr', 'Loos_Val', 'Acc_Tr', 'Acc_Val')\n",
    "for freezeLayers in freezeLayersValues: # \n",
    "    for learning in learningValues:\n",
    "        for mom in monValues:\n",
    "            for iepochs in epochsValues:\n",
    "                for ibatch_size in batch_sizeValues:\n",
    "                    try:\n",
    "                        # Try to execute the fine tuning function\n",
    "                        FineTunningVGG(iepochs, ibatch_size, learning, mom, freezeLayers)\n",
    "                    except:\n",
    "                        # If any error\n",
    "                        print('==> Error:', freezeLayers, learning, mom, iepochs, ibatch_size)\n",
    "\n",
    "# Print total execution time\n",
    "print(\"Total time: %0.1f mins ---\" % ((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `learning rate=0.0005` and `momentum=0.9` it is possible to obtain `94.9%` validation accuracy (96.2% training accuracy). Let's try some close values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freeze Learning Momentum epochs batch_size Loss_Tr Loos_Val Acc_Tr Acc_Val\n",
      "Found 910 images belonging to 2 classes.\n",
      "Found 302 images belonging to 2 classes.\n",
      "Epoch 00022: early stopping\n",
      "Training time: 0.9 mins ---\n",
      "15 0.0002 0.9 100 64 0.1575070135295391 0.19659276492893696 0.9397321428571429 0.9375\n",
      "Found 910 images belonging to 2 classes.\n",
      "Found 302 images belonging to 2 classes.\n",
      "Epoch 00034: early stopping\n",
      "Training time: 1.3 mins ---\n",
      "15 0.0003 0.9 100 64 0.11700797293867383 0.14799168519675732 0.953125 0.94921875\n",
      "Found 910 images belonging to 2 classes.\n",
      "Found 302 images belonging to 2 classes.\n",
      "Epoch 00025: early stopping\n",
      "Training time: 1.0 mins ---\n",
      "15 0.0004 0.9 100 64 0.15608231403997966 0.18702777475118637 0.9397321428571429 0.94140625\n",
      "Found 910 images belonging to 2 classes.\n",
      "Found 302 images belonging to 2 classes.\n",
      "Epoch 00024: early stopping\n",
      "Training time: 0.9 mins ---\n",
      "15 0.0006 0.9 100 64 0.27273742854595184 0.33562444150447845 0.8895089285714286 0.8828125\n",
      "Found 910 images belonging to 2 classes.\n",
      "Found 302 images belonging to 2 classes.\n",
      "Epoch 00018: early stopping\n",
      "Training time: 0.7 mins ---\n",
      "15 0.0007 0.9 100 64 0.13509203387158258 0.2285628318786621 0.9497767857142857 0.9375\n",
      "Total time: 5.2 mins ---\n"
     ]
    }
   ],
   "source": [
    "# Start total timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Change your hyperparamters to search for\n",
    "freezeLayersValues = [15] # 15 = freeze last Conv block, 11 = freeze last 2 Conv blocks\n",
    "learningValues = [2e-4, 3e-4, 4e-4, 6e-4, 7e-4]\n",
    "monValues = [0.9]\n",
    "epochsValues = [100]\n",
    "batch_sizeValues = [64]\n",
    "\n",
    "# Print a header for results\n",
    "print('Freeze', 'Learning', 'Momentum', 'epochs', 'batch_size', 'Loss_Tr', 'Loos_Val', 'Acc_Tr', 'Acc_Val')\n",
    "for freezeLayers in freezeLayersValues: # \n",
    "    for learning in learningValues:\n",
    "        for mom in monValues:\n",
    "            for iepochs in epochsValues:\n",
    "                for ibatch_size in batch_sizeValues:\n",
    "                    try:\n",
    "                        # Try to execute the fine tuning function\n",
    "                        FineTunningVGG(iepochs, ibatch_size, learning, mom, freezeLayers)\n",
    "                    except:\n",
    "                        # If any error\n",
    "                        print('==> Error:', freezeLayers, learning, mom, iepochs, ibatch_size)\n",
    "\n",
    "# Print total execution time\n",
    "print(\"Total time: %0.1f mins ---\" % ((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you remove the callbacks and use 200 epochs, you will be able to obtain even better accuracies:\n",
    "* 15 0.0005 0.8 200 64 0.03348573550049748 0.11928138509392738 0.9888392857142857 0.96875\n",
    "* 15 0.0005 0.9 200 64 0.022504917612033232 0.1295782057568431 0.9921875 0.96875\n",
    "* 15 0.0002 0.9 200 64 0.037957151753029654 0.11038850899785757 0.9888392857142857 0.98046875\n",
    "\n",
    "Thus, trainig 8 minutes the last Conv block and FC layer, you can obtain a `validation accuracy of 98%`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last 2 Conv block + FC training\n",
    "\n",
    "Let's see what ACC we could obtain if we train the last 2 Conv blocks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 910 images belonging to 2 classes.\n",
      "Found 302 images belonging to 2 classes.\n",
      "Epoch 00027: early stopping\n",
      "Training time: 1.3 mins ---\n",
      "11 0.0001 0.9 200 64 0.13032949502979005 0.18357415683567524 0.9553571428571429 0.9375\n"
     ]
    }
   ],
   "source": [
    "FineTunningVGG(200, 64, 1e-4,  0.9, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we expected, training more layers we are obtaining better results but the complexity of the model and the small dataset are starting to generate overfitting. Let's check different parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1d7e807cae61>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Start total timer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Change your hyperparamters to search for\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfreezeLayersValues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# 15 = freeze last Conv block, 11 = freeze last 2 Conv blocks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "# Start total timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Change your hyperparamters to search for\n",
    "freezeLayersValues = [11] # 15 = freeze last Conv block, 11 = freeze last 2 Conv blocks\n",
    "learningValues = [1e-6, 1e-5, 1e-4, 5e-4]\n",
    "monValues = [0.8, 0.9]\n",
    "epochsValues = [100]\n",
    "batch_sizeValues = [64]\n",
    "\n",
    "\n",
    "# Print a header for results\n",
    "print('Freeze', 'Learning', 'Momentum', 'epochs', 'batch_size', 'Loss_Tr', 'Loos_Val', 'Acc_Tr', 'Acc_Val')\n",
    "for freezeLayers in freezeLayersValues: # \n",
    "    for learning in learningValues:\n",
    "        for mom in monValues:\n",
    "            for iepochs in epochsValues:\n",
    "                for ibatch_size in batch_sizeValues:\n",
    "                    try:\n",
    "                        # Try to execute the fine tuning function\n",
    "                        FineTunningVGG(iepochs, ibatch_size, learning, mom, freezeLayers)\n",
    "                    except:\n",
    "                        # If any error\n",
    "                        print('==> Error:', freezeLayers, learning, mom, iepochs, ibatch_size)\n",
    "\n",
    "# Print total execution time\n",
    "print(\"Total time: %0.1f mins ---\" % ((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you remove the callbacks and use 200 epochs, you will be able to obtain even better accuracies over 96%.\n",
    "\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "* If you apply the fine tuning for the last conv block of VGG16 + FC (top model) you can obtain an accuracy `over 98%` (learning rate = 0.0002, momentum = 0.9, batch size = 64). This values is better compare with the small CNN results (`over 92%`).\n",
    "* The search space was limited and possible additional hyperparameter combinations should be tested including drop rate, optimizer or the base model (not only VGG16, it could be Inception, etc.).\n",
    "\n",
    "If you need a classifier to detect polyps in your colonoscopy images, you could try a small CNN with only few hiden layers. If you need accuracy over 98% you should try fine tuning.\n",
    "\n",
    "Let's find polyps into a colonoscopy image in the next script ([6-WindowsPolypsDetection.ipynb](6-WindowsPolypsDetection.ipynb)).\n",
    "\n",
    "Have fun with DL! @muntisa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acknowledgements\n",
    "\n",
    "I gratefully acknowledge the support of NVIDIA Corporation with the donation of the Titan Xp GPU used for this research ([https://developer.nvidia.com/academic_gpu_seeding](https://developer.nvidia.com/academic_gpu_seeding))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
